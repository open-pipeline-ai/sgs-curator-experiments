# SGS Curator App - Experiments

Experimental notebooks and prototypes for the SGS Curator App project, exploring chunking strategies, retrieval methods, and contradiction detection workflows.

## ğŸ¯ Purpose

This repository contains Jupyter notebooks and Python scripts used to:
- Evaluate different chunking strategies
- Test embedding models and retrieval approaches
- Prototype contradiction detection workflows
- Benchmark components before productionization
- Share experimental findings with the team

## ğŸ“ Repository Structure

```
sgs-curator-experiments/
â”œâ”€â”€ archive/                      # Archived/deprecated experiments
â”œâ”€â”€ chunking/                     # Chunking strategy experiments
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ chunking_exercise_jp.ipynb
â”œâ”€â”€ retrieval/                    # Retrieval and embedding experiments
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ agents/                       # Agent framework evaluations
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ autogen-ms/              # Microsoft's AutoGen
â”‚   â”œâ”€â”€ ag2/                     # Community fork (AutoGen v2)
â”‚   â”œâ”€â”€ crewai/                  # CrewAI framework
â”‚   â”œâ”€â”€ langgraph/               # LangGraph
â”‚   â”œâ”€â”€ langchain-agents/        # LangChain agents
â”‚   â”œâ”€â”€ pure-python/             # Custom implementations
â”‚   â””â”€â”€ comparison/              # Cross-framework analysis
â”œâ”€â”€ data/                         # Test datasets
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ shared/                       # Shared utility code
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ requirements.txt              # Common dependencies
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

# ğŸ““ Available Notebooks & Scripts

### Chunking
- **chunking_exercise_jp.ipynb** - Evaluates how different chunking strategies (fixed-size, recursive, semantic) affect the ability to detect contradictions using semantic similarity between chunks

### Retrieval
- Coming soon...

### Agents
- See [agents/README.md](agents/README.md) for framework evaluations
- Both notebooks and scripts welcome

### Contradiction Detection
- Coming soon...


## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- Jupyter Lab or Jupyter Notebook

### Installation

```bash
# Clone the repository
git clone https://github.com/open-pipeline-ai/sgs-curator-experiments.git
cd sgs-curator-experiments

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter
jupyter lab
```

### Running Notebooks & Scripts

Navigate to the appropriate directory (`chunking/`, `retrieval/`, `agents/`, etc.) and open any `.ipynb` file or run any `.py` script.

**For notebooks:**
```bash
jupyter lab chunking/
```

**For scripts:**
```bash
python chunking/my_experiment.py
```

Each notebook includes:
- Purpose and scope
- Workflow overview
- Step-by-step implementation
- Results and analysis

## ğŸ“Š Datasets

Test datasets follow the CuratorApp structure for evaluating chunking and contradiction detection.

Place datasets in `data/sample_datasets/` following the structure:
```
data/
â””â”€â”€ sample_datasets/
    â”œâ”€â”€ contradictory_docs/
    â”œâ”€â”€ consistent_docs/
    â””â”€â”€ mixed_scenarios/
```

**Note:** Large datasets should not be committed. Use `.gitignore` to exclude them.


## ğŸ¤ Contributing Experiments

We welcome experimental contributions! Here's how to add your work:

### Adding Your Own Notebook

You can commit **your own new notebooks or scripts** directly to `main` without a PR (for changes to existing notebooks or shared resources, see below):

1. **Create your notebook or script** in the appropriate directory:
   ```bash
   # Navigate to the right category
   cd chunking/  # or retrieval/, agents/, etc.
   
   # Create your notebook (use descriptive naming)
   jupyter lab
   ```

2. **Naming convention:** Use `{topic}_{your_initials}.ipynb`
   - âœ… Good: `semantic_chunking_jp.ipynb`, `agentic_retrieval_rc.ipynb`
   - âŒ Avoid: `test.ipynb`, `notebook1.ipynb`, `final_final.ipynb`

3. **Add context** at the top of your notebook:
   - Title and purpose
   - Your name/initials
   - Date created
   - Key dependencies

4. **Commit directly:**
   ```bash
   git add chunking/my_experiment_jp.ipynb
   git commit -m "feat: add semantic chunking experiment"
   git push origin main
   ```

### Notebook Ownership

- ğŸ““ **Your notebooks** = Your workspace. Commit freely, iterate quickly.
- ğŸ¤ **Others' notebooks** = Read-only. Don't modify without asking first.
- ğŸ”„ **Want to build on someone's work?** Create your own variant (e.g., `semantic_chunking_v2_rc.ipynb`)

### When to Use Pull Requests

**Always create a PR for:**

- âœ… Modifying **someone else's existing notebook** (ask them first!)
- âœ… Modifying **your own notebook** if others are using/referencing it
- âœ… README files (any directory)
- âœ… `requirements.txt` (adding new dependencies)
- âœ… Shared utilities (`shared/*.py`)
- âœ… Documentation or guidelines

**Direct commit to `main` is fine for:**

- âœ… Your own new notebook
- âœ… Updates to your own notebook that no one else is using
- âœ… Quick fixes to your own work (typos, small improvements)

**Why?** Shared resources affect everyone, so they deserve review.

### Workflow for Shared Changes

```bash
# 1. Create a branch
git checkout -b docs/update-retrieval-readme

# 2. Make changes
# Edit files...

# 3. Commit and push
git add .
git commit -m "docs: clarify retrieval workflow"
git push origin docs/update-retrieval-readme

# 4. Create PR on GitHub
# Request review from affected team members
```

### Keeping Dependencies Updated

When adding new libraries to your notebook:

1. **Test locally first** to ensure they work
2. **Update requirements.txt** via PR
3. **Document version** if specific version is needed
4. **Consider conda users** - stick to pip-installable packages when possible

Example PR:
```bash
git checkout -b deps/add-plotly
# Add plotly>=5.14.0 to requirements.txt
git commit -m "deps: add plotly for visualization"
git push origin deps/add-plotly
# Create PR
```

### Collaboration Tips

- ğŸ’¬ **Discuss big ideas** in GitHub Issues/Discussions before implementing
- ğŸ·ï¸ **Tag your notebooks** with keywords in the filename or README
- ğŸ“Š **Share findings** by updating the relevant directory README
- ğŸ”— **Link to production code** if your experiment informs a toolkit feature
- ğŸ§¹ **Archive old notebooks** - move to `notebooks/archive/` if no longer relevant

### Quality Guidelines (Suggestions, Not Requirements)

- Include purpose and methodology at the top
- Document key findings or insights
- Add visualizations where helpful
- Keep notebooks focused (one experiment per notebook)
- Clear cell outputs before committing (optional - depends on preference)
- Use markdown cells to explain your thinking

### Getting Feedback

Want feedback on your experiment?

1. **Mention in Slack/email** - "Added new chunking experiment in notebooks/chunking/"
2. **Create a GitHub Discussion** - For open-ended questions
3. **Create an Issue** - If you found something that should be addressed
4. **Schedule a review** - Demo your notebook in a team meeting

## ğŸ“ Notebook Guidelines

When creating notebooks:

- âœ… Include clear purpose and scope at the top
- âœ… Document all dependencies and versions
- âœ… Use markdown cells to explain methodology
- âœ… Include results and analysis sections
- âœ… Reference datasets and external resources
- âœ… Keep notebooks focused on one experiment
- âœ… Add visualizations where helpful
- âŒ Don't commit large datasets or model files
- âŒ Don't include sensitive API keys (use environment variables)

## ğŸ› ï¸ Common Dependencies

Key libraries used across notebooks:

- **LangChain** - Text splitting and chunking
- **Sentence Transformers** - Embedding models
- **VLLM** - Local LLM inference
- **NumPy/Pandas** - Data manipulation
- **Matplotlib/Seaborn** - Visualization
- **scikit-learn** - Similarity metrics

See `requirements.txt` for complete list.

## ğŸ“„ License

This project is licensed under the GNU Lesser General Public License v3.0 or later (LGPLv3+) - see the [LICENSE](LICENSE) file for details.

## ğŸ¤” Questions?

- Open an issue in this repository
- Refer to the main [Curator App documentation](TBD)
- Contact the project maintainers

---

**Note:** This is an experimental repository. Production-ready code should be contributed to the respective toolkit repositories (chunking-toolkit, retrieval-toolkit).

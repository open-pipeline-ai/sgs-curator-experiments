# SGS Curator App - Experiments

Experimental notebooks and prototypes for the SGS Curator App project, exploring chunking strategies, retrieval methods, and contradiction detection workflows.

## ğŸ¯ Purpose

This repository contains Jupyter notebooks used to:
- Evaluate different chunking strategies
- Test embedding models and retrieval approaches
- Prototype contradiction detection workflows
- Benchmark components before productionization
- Share experimental findings with the team

## ğŸ“ Repository Structure

```
sgs-curator-experiments/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ chunking/              # Chunking strategy experiments
â”‚   â”œâ”€â”€ retrieval/             # Retrieval and embedding experiments
â”‚   â”œâ”€â”€ contradiction_detection/  # Contradiction detection workflows
â”‚   â””â”€â”€ end_to_end/            # Full pipeline experiments
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_datasets/       # Test datasets (following Redmine structure)
â”œâ”€â”€ shared/                    # Shared utility code
â””â”€â”€ requirements.txt           # Common dependencies
```

## ğŸ““ Available Notebooks

### Chunking
- **chunking_exercise.ipynb** - Evaluates how different chunking strategies (fixed-size, recursive, semantic) affect the ability to detect contradictions using semantic similarity between chunks

### Retrieval
- Coming soon...

### Contradiction Detection
- Coming soon...

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- Jupyter Lab or Jupyter Notebook

### Installation

```bash
# Clone the repository
git clone https://github.com/open-pipeline-ai/sgs-curator-experiments.git
cd sgs-curator-experiments

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter
jupyter lab
```

### Running Notebooks

Navigate to the `notebooks/` directory and open any `.ipynb` file.

Each notebook includes:
- Purpose and scope
- Workflow overview
- Step-by-step implementation
- Results and analysis

## ğŸ“Š Datasets

Test datasets follow the CuratorApp structure for evaluating chunking and contradiction detection.

Place datasets in `data/sample_datasets/` following the structure:
```
data/
â””â”€â”€ sample_datasets/
    â”œâ”€â”€ contradictory_docs/
    â”œâ”€â”€ consistent_docs/
    â””â”€â”€ mixed_scenarios/
```

**Note:** Large datasets should not be committed. Use `.gitignore` to exclude them.


## ğŸ¤ Contributing Experiments

We welcome experimental contributions! Here's how to add your work:

### Adding Your Own Notebook

You can commit **your own new notebooks** directly to `main` without a PR (for changes to existing notebooks or shared resources, see below):

1. **Create your notebook** in the appropriate directory:
   ```bash
   # Navigate to the right category
   cd notebooks/chunking/  # or retrieval/, contradiction_detection/, etc.
   
   # Create your notebook (use descriptive naming)
   jupyter lab
   ```

2. **Naming convention:** Use `{topic}_{your_initials}.ipynb`
   - âœ… Good: `semantic_chunking_jp.ipynb`, `agentic_retrieval_rc.ipynb`
   - âŒ Avoid: `test.ipynb`, `notebook1.ipynb`, `final_final.ipynb`

3. **Add context** at the top of your notebook:
   - Title and purpose
   - Your name/initials
   - Date created
   - Key dependencies

4. **Commit directly:**
   ```bash
   git add notebooks/chunking/my_experiment_jp.ipynb
   git commit -m "feat: add semantic chunking experiment"
   git push origin main
    ```

### Notebook Ownership

- ğŸ““ **Your notebooks** = Your workspace. Commit freely, iterate quickly.
- ğŸ¤ **Others' notebooks** = Read-only. Don't modify without asking first.
- ğŸ”„ **Want to build on someone's work?** Create your own variant (e.g., `semantic_chunking_v2_rc.ipynb`)

### When to Use Pull Requests

**Create a PR for changes to shared resources:**

- âœ… README files (any directory)
- âœ… `requirements.txt` (adding new dependencies)
- âœ… Shared utilities (`shared/*.py`)
- âœ… Someone else's notebook (ask them first!)
- âœ… Documentation or guidelines

**Why?** Shared resources affect everyone, so they deserve review.

### Workflow for Shared Changes

```bash
# 1. Create a branch
git checkout -b docs/update-retrieval-readme

# 2. Make changes
# Edit files...

# 3. Commit and push
git add .
git commit -m "docs: clarify retrieval workflow"
git push origin docs/update-retrieval-readme

# 4. Create PR on GitHub
# Request review from affected team members
```

### Keeping Dependencies Updated

When adding new libraries to your notebook:

1. **Test locally first** to ensure they work
2. **Update requirements.txt** via PR
3. **Document version** if specific version is needed
4. **Consider conda users** - stick to pip-installable packages when possible

Example PR:
```bash
git checkout -b deps/add-plotly
# Add plotly>=5.14.0 to requirements.txt
git commit -m "deps: add plotly for visualization"
git push origin deps/add-plotly
# Create PR
```

### Collaboration Tips

- ğŸ’¬ **Discuss big ideas** in GitHub Issues/Discussions before implementing
- ğŸ·ï¸ **Tag your notebooks** with keywords in the filename or README
- ğŸ“Š **Share findings** by updating the relevant directory README
- ğŸ”— **Link to production code** if your experiment informs a toolkit feature
- ğŸ§¹ **Archive old notebooks** - move to `notebooks/archive/` if no longer relevant

### Quality Guidelines (Suggestions, Not Requirements)

- Include purpose and methodology at the top
- Document key findings or insights
- Add visualizations where helpful
- Keep notebooks focused (one experiment per notebook)
- Clear cell outputs before committing (optional - depends on preference)
- Use markdown cells to explain your thinking

### Getting Feedback

Want feedback on your experiment?

1. **Mention in Slack/email** - "Added new chunking experiment in notebooks/chunking/"
2. **Create a GitHub Discussion** - For open-ended questions
3. **Create an Issue** - If you found something that should be addressed
4. **Schedule a review** - Demo your notebook in a team meeting

## ğŸ“ Notebook Guidelines

When creating notebooks:

- âœ… Include clear purpose and scope at the top
- âœ… Document all dependencies and versions
- âœ… Use markdown cells to explain methodology
- âœ… Include results and analysis sections
- âœ… Reference datasets and external resources
- âœ… Keep notebooks focused on one experiment
- âœ… Add visualizations where helpful
- âŒ Don't commit large datasets or model files
- âŒ Don't include sensitive API keys (use environment variables)

## ğŸ› ï¸ Common Dependencies

Key libraries used across notebooks:

- **LangChain** - Text splitting and chunking
- **Sentence Transformers** - Embedding models
- **VLLM** - Local LLM inference
- **NumPy/Pandas** - Data manipulation
- **Matplotlib/Seaborn** - Visualization
- **scikit-learn** - Similarity metrics

See `requirements.txt` for complete list.

## ğŸ“„ License

This project is licensed under the GNU Lesser General Public License v3.0 or later (LGPLv3+) - see the [LICENSE](LICENSE) file for details.

## ğŸ¤” Questions?

- Open an issue in this repository
- Refer to the main [Curator App documentation](TBD)
- Contact the project maintainers

---

**Note:** This is an experimental repository. Production-ready code should be contributed to the respective toolkit repositories (chunking-toolkit, retrieval-toolkit).